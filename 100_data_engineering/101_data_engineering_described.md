# Data Engineering Described

## Basics

Data Engineer's goals.
```
A data engineer has several top-level goals across the data lifecycle: produce optimum
ROI and reduce costs (financial and opportunity), reduce risk (security, data quality),
and maximize data value and utility.
```

History of data engineering.
```
- Bill Inmon officially coining the term data warehouse in 1989.
- IBM developed the relational database and Structured Query Language (SQL).
- Oracle popularized this technology.
- Data warehousing ushered in the first age of scalable analytics, with new massively parallel processing (MPP) databases that use multiple processors to crunch large amounts of data coming on the market and supporting unprecedented volumes of data.
- The internet went mainstream around the mid-1990s, creating a whole new generation of web-first companies such as AOL, Yahoo, and Amazon. The new generation of the systems must be cost-effective, scalable, available, and reliable.
- In 2003, Google published a paper on the Google File System, and shortly after that, in 2004, a paper on MapReduce, an ultra-scalable data-processing paradigm.
- Yahoo to develop Apache Hadoop in 2006.
- Around the same time, Amazon created Amazon Web Services (AWS), becoming the first popular public cloud.
- Engineers could choose the latest and greatest—Hadoop, Apache Pig, Apache Hive, Dremel, Apache HBase, Apache Storm, Apache Cassandra, Apache Spark, Presto, and numerous other new technologies that came on the scene. Traditional enterprise-oriented and GUI-based data tools suddenly felt outmoded.
- Hadoop ecosystem including Hadoop, YARN, Hadoop Distributed File System (HDFS), and MapReduce—big data engineers had to be proficient in software development and low-level infrastructure hacking,
- Despite the term’s popularity, big data has lost steam. What happened? One word: simplification. Despite the power and sophistication of open source big data tools, managing them was a lot of work and required constant attention. Often, companies employed entire teams of big data engineers, costing millions of dollars a year, to babysit these platforms. Big data engineers often spent excessive time maintaining complicated tooling and arguably not as much time delivering the business’s insights and value.
- Today, data is moving faster than ever and growing ever larger, but big data processing has become so accessible that it no longer merits a separate term; every company aims to solve its data problems, regardless of actual data size. Big data engineers are now simply data engineers.
- Whereas data engineers historically tended to the low-level details of monolithic frameworks such as Hadoop, Spark, or Informatica, the trend is moving toward decentralized, modularized, managed, and highly abstracted tools.
```


## Data Engineer

What are other data related positions in a team?

```
Upstream stakeholders:
- Data architects
- Software engineers
- DevOps engineers

Downstream stakeholders:
- Data scientists
- Data analysts
- Machine learning engineers and AI researchers
```

What are the skills of DE?
```
- security
- data management
- DataOps
- data architecture
- software engineering

Must constantly optimize along the axes of cost, agility, scalability, simplicity, reuse, and interoperability.
```


What is Data maturity? Name 3 stages and describe.

```
Data maturity is the progression toward higher data utilization, capabilities, and
integration across the organization.

Three stages:
- starting with data
- scaling with data
- leading with data
```


