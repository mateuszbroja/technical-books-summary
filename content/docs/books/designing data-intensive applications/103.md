---
weight: 3
title: "03: Storage and Retrieval"
bookHidden: true
---

# Storage and Retrieval
---

*On the most fundamental level, a database needs to do two things: when you give it some data, it should store the data, and when you ask it again later, it should give the data back to you.*



two families of storage engines: log-structured storage engines, and page-oriented storage engines
such as B-trees.

## Data Structures That Power Your Database

Simplest database, as a key-value store:

```bash
#!/bin/bash

db_set () {
	echo "$1,$2" >> database
}

db_get () {
	grep "^$1," database | sed -e "s/^$1,//" | tail -n 1
}
```

The key and value can be anything you like (ex. JSON document).

Every call to db_set appends to the end of the file, so if you update a key several, times, the old versions of the value are not overwritten—you need to look at the last occurrence of a key (`tail -n 1`).


many databases internally use a log

DEF
log is used in the more general sense: an append-only
sequence of records


Real databases have more issues to deal with (such as concurrency control, reclaiming
disk space so that the log doesn’t grow forever, and handling errors and partially
written records), but the basic principle is the same.

Write:
pretty good performance for something that is so
simple, because appending to a file is generally very efficient.

Read:
terrible performance
Every time you want to look up a key, db_get
has to scan the entire database file from beginning to end, looking for occurrences of
the key. In algorithmic terms, the cost of a lookup is O(n): if you double the number
of records n in your database, a lookup takes twice as long.


In order to efficiently find the value for a particular key in the database, we need a
different data structure: an index.


## Indexes

the general idea behind them is to keep some
additional metadata on the side, which acts as a signpost and helps you to locate the
data you want.

DEF
Index

An index is an additional structure that is derived from the primary data. Many databases
allow you to add and remove indexes, and this doesn’t affect the contents of the
database; it only affects the performance of queries. Maintaining additional structures
incurs overhead, especially on writes. For writes, it’s hard to beat the performance of
simply appending to a file, because that’s the simplest possible write operation. Any
kind of index usually slows down writes, because the index also needs to be updated
every time data is written.

This is an important trade-off in storage systems: well-chosen indexes speed up read
queries, but every index slows down writes.

For this reason, databases don’t usually
index everything by default, but require you—the application developer or database
administrator—to choose indexes manually, using your knowledge of the application’s
typical query patterns.

On the OLTP side, we saw storage engines from two main schools of thought:
• The log-structured school, which only permits appending to files and deleting
obsolete files, but never updates a file that has been written. Bitcask, SSTables,
LSM-trees, LevelDB, Cassandra, HBase, Lucene, and others belong to this group.
• The update-in-place school, which treats the disk as a set of fixed-size pages that
can be overwritten. B-trees are the biggest example of this philosophy, being used
in all major relational databases and also many nonrelational ones.

Log-structured storage engines are a comparatively recent development. Their key
idea is that they systematically turn random-access writes into sequential writes on
disk, which enables higher write throughput due to the performance characteristics
of hard drives and SSDs.

### Hash indexes


### SSTables and LSM-Trees



### Comparing B-Trees and LSM-Trees


### Other Indexing Structures

#### Storing values within the index

#### Multi-column indexes

#### Full-text search and fuzzy indexes

#### Keeping everything in memory


## Transaction Processing or Analytics?

storage engines fall into two broad categories: those optimized
for transaction processing (OLTP), and those optimized for analytics (OLAP).

There are big differences between the access patterns in those use cases:
• OLTP systems are typically user-facing, which means that they may see a huge
volume of requests. In order to handle the load, applications usually only touch a
small number of records in each query. The application requests records using
some kind of key, and the storage engine uses an index to find the data for the
requested key. Disk seek time is often the bottleneck here.
• Data warehouses and similar analytic systems are less well known, because they
are primarily used by business analysts, not by end users. They handle a much
lower volume of queries than OLTP systems, but each query is typically very
demanding, requiring many millions of records to be scanned in a short time.
Disk bandwidth (not seek time) is often the bottleneck here, and columnoriented
storage is an increasingly popular solution for this kind of workload.

This background illustrated why analytic
workloads are so different from OLTP: when your queries require sequentially scanning
across a large number of rows, indexes are much less relevant. Instead it
becomes important to encode data very compactly, to minimize the amount of data
that the query needs to read from disk. We discussed how column-oriented storage
helps achieve this goal.

### Data Warehousing

#### The divergence between OLTP databases and data warehouses

#### Stars and Snowflakes: Schemas for Analytics

### Column-Oriented Storage



#### Column Compression

#### Sort Order in Column Storage

#### Writing to Column-Oriented Storage

### Aggregation: Data Cubes and Materialized Views