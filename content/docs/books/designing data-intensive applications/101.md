---
weight: 1
title: "01: Reliable, Scalable, and Maintainable Applications"
bookHidden: false
---

# Reliable, Scalable, and Maintainable Applications
---

An application has to meet various requirements in order to be useful. There are
functional requirements (what it should do, such as allowing data to be stored,
retrieved, searched, and processed in various ways), and some nonfunctional requirements
(general properties like security, reliability, compliance, scalability, compatibility,
and maintainability).

Many applications today are data-intensive, as opposed to compute-intensive. Raw
CPU power is rarely a limiting factor for these applications—bigger problems are
usually the amount of data, the complexity of data, and the speed at which it is
changing.


For example, many applications need to:
• Store data so that they, or another application, can find it again later (databases)
• Remember the result of an expensive operation, to speed up reads (caches)
• Allow users to search data by keyword or filter it in various ways (search indexes)
• Send a message to another process, to be handled asynchronously (stream processing)
• Periodically crunch a large amount of accumulated data (batch processing)


there are datastores that are also used as message
queues (Redis), and there are message queues with database-like durability guarantees
(Apache Kafka).


## Reliability

Reliability means making systems work correctly, even when faults occur

The things that can go wrong are called faults, and systems that anticipate faults and
can cope with them are called fault-tolerant or resilient. makes sense to talk
about tolerating certain types of faults.

Note that a fault is not the same as a failure [2]. A fault is usually defined as one component
of the system deviating from its spec, whereas a failure is when the system as a
whole stops providing the required service to the user. prevent faults from causing failures

Many critical bugs are actually due to poor error
handling

### Hardware Faults
Hard disks crash, RAM becomes faulty, the power grid has a blackout, someone
unplugs the wrong network cable.
Hard disks are reported as having a mean time to failure (MTTF) of about 10 to 50
years

Our first response is usually to add redundancy to the individual hardware components
in order to reduce the failure rate of the system.

Hence there is a move toward systems that can tolerate the loss of entire machine


### Software Errors
systematic error within the system [8]. Such faults are
harder to anticipate, and because they are correlated across nodes, they tend to cause
many more system failures than uncorrelated hardware faults

Lots of
small things can help: carefully thinking about assumptions and interactions in the
system; thorough testing; process isolation; allowing processes to crash and restart;
measuring, monitoring, and analyzing system behavior in production


### Human Errors
configuration errors by operators were the leading cause of outages, whereas hardware
faults (servers or network) played a role in only 10–25% of outages

Design systems in a way that minimizes opportunities for error. For example,
well-designed abstractions, APIs, and admin interfaces
provide fully featured non-production
sandbox environments where people can explore and experiment safely
Test thoroughly at all levels, from unit tests to whole-system integration tests and
manual tests
Allow quick and easy recovery
Set up detailed and clear monitoring
Implement good management practices and training

## Scalability

Scalability means having strategies for keeping performance good, even when load
increases.
In a scalable system, you can add processing capacity in order to remain
reliable under high load
One common reason for degradation is increased load

Scalability is the term we use to describe a system’s ability to cope with increased
load.

Describing Load
Load can be described
with a few numbers which we call load parameters. The best choice of parameters
depends on the architecture of your system: it may be requests per second to a web
server, the ratio of reads to writes in a database, the number of simultaneously active
users in a chat room, the hit rate on a cache, or something else.

consider Twitter as an example

Two of Twitter’s main operations are:
Post tweet
A user can publish a new message to their followers (4.6k requests/sec on average,
over 12k requests/sec at peak).
Home timeline
A user can view tweets posted by the people they follow (300k requests/sec).

Simply handling 12,000 writes per second (the peak rate for posting tweets) would be
fairly easy. However, Twitter’s scaling challenge is not primarily due to tweet volume,
but due to fan-outii—each user follows many people, and each user is followed by
many people. There are broadly two ways of implementing these two operations:

Posting a tweet simply inserts the new tweet into a global collection of tweets When a user requests their home timeline, look up all the people they follow,
find all the tweets for each of those users, and merge them (sorted by time).

SELECT tweets.*, users.* FROM tweets
JOIN users ON tweets.sender_id = users.id
JOIN follows ON follows.followee_id = users.id
WHERE follows.follower_id = current_user


2. Maintain a cache for each user’s home timeline—like a mailbox of tweets for
each recipient user (see Figure 1-3). When a user posts a tweet, look up all the
people who follow that user, and insert the new tweet into each of their home
timeline caches. The request to read the home timeline is then cheap, because its
result has been computed ahead of time.


The first version of Twitter used approach 1, but the systems struggled to keep up
with the load of home timeline queries, so the company switched to approach 2. This
works better because the average rate of published tweets is almost two orders of
magnitude lower than the rate of home timeline reads, and so in this case it’s preferable
to do more work at write time and less at read time.

The final twist of the Twitter anecdote: now that approach 2 is robustly implemented,
Twitter is moving to a hybrid of both approaches.

### Describing Performance
Once you have described the load on your system, you can investigate what happens
when the load increases

In a batch processing system such as Hadoop, we usually care about throughput—the
number of records we can process per second, or the total time it takes to run a job
on a dataset of a certain size.iii In online systems, what’s usually more important is the
service’s response time—that is, the time between a client sending a request and
receiving a response. It’s common to see the average response time. Usually it is better to use percentiles.

In order to figure out how bad your outliers are, you can look at higher percentiles:
the 95th, 99th, and 99.9th percentiles are common.
High percentiles of response times, also known as tail latencies, are important
because they directly affect users’ experience of the service. For example, Amazon
describes response time requirements for internal services in terms of the 99.9th percentile,
even though it only affects 1 in 1,000 requests

For example, percentiles are often used in service level objectives (SLOs) and service
level agreements (SLAs), contracts that define the expected performance and availability
of a service. An SLA may state that the service is considered to be up if it has a
median response time of less than 200 ms and a 99th percentile under 1 s (if the
response time is longer, it might as well be down), and the service may be required to
be up at least 99.9% of the time. These metrics set expectations for clients of the service
and allow customers to demand a refund if the SLA is not met.

Latency and response time are often used synonymously, but they
are not the same. The response time is what the client sees: besides
the actual time to process the request (the service time), it includes
network delays and queueing delays. Latency is the duration that a
request is waiting to be handled—during which it is latent, awaiting
service

### Approaches for Coping with Load

People often talk of a dichotomy between scaling up (vertical scaling, moving to a
more powerful machine) and scaling out (horizontal scaling, distributing the load
across multiple smaller machines). Distributing load across multiple machines is also
known as a shared-nothing architecture

using several fairly powerful
machines can still be simpler and cheaper than a large number of small virtual
machines.

Some systems are elastic, meaning that they can automatically add computing resources
when they detect a load increase, whereas other systems are scaled manually

For this reason, common wisdom until recently
was to keep your database on a single node (scale up) until scaling cost or highavailability
requirements forced you to make it distributed.


The architecture of systems that operate at large scale is usually highly specific to the
application—there is no such thing as a generic, one-size-fits-all scalable architecture
(informally known as magic scaling sauce).


An architecture that scales well for a particular application is built around assumptions
of which operations will be common and which will be rare—the load parameters.


## Maintainability

Maintainability has many facets, but in essence it’s about making life better for the
engineering and operations teams who need to work with the system

three design principles for software
systems:
Operability
Make it easy for operations teams to keep the system running smoothly.
Simplicity
Make it easy for new engineers to understand the system, by removing as much
complexity as possible from the system. (Note this is not the same as simplicity
of the user interface.)
Evolvability
Make it easy for engineers to make changes to the system in the future, adapting
it for unanticipated use cases as requirements change. Also known as extensibility,
modifiability, or plasticity.

### Operability
good
operations team typically is responsible for the following, and more [29]:
• Monitoring the health of the system and quickly restoring service if it goes into a
bad state
• Tracking down the cause of problems, such as system failures or degraded performance
• Keeping software and platforms up to date, including security patches
• Keeping tabs on how different systems affect each other
Maintaining the security of the system

Good operability means making routine tasks easy, allowing the operations team to
focus their efforts on high-value activities.


### Simplicity

A software project mired in complexity is sometimes
described as a big ball of mud

symptoms of complexity: explosion of the state space, tight
coupling of modules, tangled dependencies, inconsistent naming and terminology,
hacks aimed at solving performance problems, special-casing to work around issues
elsewhere, and many more

One of the best tools we have for removing accidental complexity is abstraction. A
good abstraction can hide a great deal of implementation detail behind a clean,
simple-to-understand façade.

For example, high-level programming languages are abstractions that hide machine
code, CPU registers, and syscalls. SQL is an abstraction that hides complex on-disk
and in-memory data structures, concurrent requests from other clients, and inconsistencies
after crashes.


### Evolvability


In terms of organizational processes, Agile working patterns provide a framework for
adapting to change. The Agile community has also developed technical tools and patterns
that are helpful when developing software in a frequently changing environment,
such as test-driven development (TDD) and refactoring

The ease with which you can modify a data system, and adapt it to changing requirements,
is closely linked to its simplicity and its abstractions:

word to refer to agility on a data system
level: evolvability